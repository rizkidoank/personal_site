<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Language" content="en">

    <meta name="author" content="Rizki Rizki">
    <meta name="description" content="Beberapa bulan ini saya mengembangkan proyek berupa dasbor untuk monitoring toko online dari beberapa e-commerce. Salah satu bagian penting yang ada di proyek ini yaitu crawler / scraper. Crawler digunakan untuk akuisisi data yang selanjutnya akan diolah menjadi data penjualan terintegrasi untuk pemilik toko.
Saat ini ada beberapa framework crawler yang banyak digunakan misal saja Apache Nutch yang memiliki keunggulan untuk dapat bekerja pada Hadoop Cluster (versi 2), dan Scrapy yang berbasis Python dan mendukung mode terdistribusi dengan frontera (HBase).">
    <meta name="keywords" content="blog,developer,personal,devops">

    

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Pengalaman Membuat E-Commerce Scraper dengan Scrapy"/>
<meta name="twitter:description" content="Beberapa bulan ini saya mengembangkan proyek berupa dasbor untuk monitoring toko online dari beberapa e-commerce. Salah satu bagian penting yang ada di proyek ini yaitu crawler / scraper. Crawler digunakan untuk akuisisi data yang selanjutnya akan diolah menjadi data penjualan terintegrasi untuk pemilik toko.
Saat ini ada beberapa framework crawler yang banyak digunakan misal saja Apache Nutch yang memiliki keunggulan untuk dapat bekerja pada Hadoop Cluster (versi 2), dan Scrapy yang berbasis Python dan mendukung mode terdistribusi dengan frontera (HBase)."/>

    <meta property="og:title" content="Pengalaman Membuat E-Commerce Scraper dengan Scrapy" />
<meta property="og:description" content="Beberapa bulan ini saya mengembangkan proyek berupa dasbor untuk monitoring toko online dari beberapa e-commerce. Salah satu bagian penting yang ada di proyek ini yaitu crawler / scraper. Crawler digunakan untuk akuisisi data yang selanjutnya akan diolah menjadi data penjualan terintegrasi untuk pemilik toko.
Saat ini ada beberapa framework crawler yang banyak digunakan misal saja Apache Nutch yang memiliki keunggulan untuk dapat bekerja pada Hadoop Cluster (versi 2), dan Scrapy yang berbasis Python dan mendukung mode terdistribusi dengan frontera (HBase)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rizkidoank.com/2016/11/03/pengalaman-membuat-e-commerce-scraper-dengan-scrapy/" />
<meta property="article:published_time" content="2016-11-03T05:01:42+00:00" />
<meta property="article:modified_time" content="2016-11-03T05:01:42+00:00" />


    
      <base href="https://rizkidoank.com/2016/11/03/pengalaman-membuat-e-commerce-scraper-dengan-scrapy/">
    
    <title>
  Pengalaman Membuat E-Commerce Scraper dengan Scrapy · rizkidoank&#39;s Blog
</title>

    
      <link rel="canonical" href="https://rizkidoank.com/2016/11/03/pengalaman-membuat-e-commerce-scraper-dengan-scrapy/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css" integrity="sha384-Bfad6CLCknfcloXFOyFnlgtENryhrpZCe29RTifKEixXQZ38WheV+i/6YWSzkz3V" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.3219ef62ae52679b7a9c19043171c3cd9f523628c2a65f3ef247ee18836bc90b.css" integrity="sha256-MhnvYq5SZ5t6nBkEMXHDzZ9SNijCpl8&#43;8kfuGINryQs=" crossorigin="anonymous" media="screen" />
    

    

    

    

    

    <link rel="icon" type="image/png" href="https://rizkidoank.com/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://rizkidoank.com/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.72.0" />
  </head>

  
  
  <body class="colorscheme-light"
        onload=""
  >
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      rizkidoank&#39;s Blog
    </a>
    
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://rizkidoank.com/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://rizkidoank.com/about/">About</a>
          </li>
        
      
      
    </ul>
    
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Pengalaman Membuat E-Commerce Scraper dengan Scrapy</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2016-11-03T05:01:42Z'>
                November 3, 2016
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              3-minute read
            </span>
          </div>
          
          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="/tags/programming/">programming</a>
      <span class="separator">•</span>
    <a href="/tags/web-scraping/">web-scraping</a>
      <span class="separator">•</span>
    <a href="/tags/service/">service</a></div>

        </div>
      </header>

      <div>
        
        <p>Beberapa bulan ini saya mengembangkan proyek berupa dasbor untuk monitoring toko online dari beberapa e-commerce. Salah satu bagian penting yang ada di proyek ini yaitu crawler / scraper. Crawler digunakan untuk akuisisi data yang selanjutnya akan diolah menjadi data penjualan terintegrasi untuk pemilik toko.</p>
<p>Saat ini ada beberapa framework crawler yang banyak digunakan misal saja Apache Nutch yang memiliki keunggulan untuk dapat bekerja pada Hadoop Cluster (versi 2), dan Scrapy yang berbasis Python dan mendukung mode terdistribusi dengan frontera (HBase). Pada awal dijalankannya proyek ini, saya menggunakan Scrapy sebagai framework crawlernya. Kenapa Scrapy? Pertama saya mulai riset dari skala kecil, kedua Scrapy cukup mudah dalam pengaplikasiannya, ketiga dapat dilakukan scaling out tanpa merubah banyak kode.</p>
<p><img src="https://rizkidoank.sgp1.digitaloceanspaces.com/rizkidoank/images/2016/11/scapy.PNG" alt="Scrapy Frontpage">
Scrapy adalah framework untuk ekstraksi data dari website. Scrapy dibangun dengan menggunakan Python. Pada Scrapy terdapat scheduler yang mengatur bagaimana crawling nanti berjalan, lalu ada Spider yang akan melakukan scraping ke laman situs tertentu, ada downloader yang mengunduh situs yang kemudian akan di parsing oleh spider, dan terakhir ada item pipeline yaitu jalur untuk penyimpanan item, yang saya gunakan yaitu json atau dikirimkan ke MongoDB.</p>
<p>Implementasi crawler dapat dilihat melalui repo saya di <a href="https://github.com/rizkidoank/shopwatch">https://github.com/rizkidoank/shopwatch</a>. Saat ini mendukung bukalapak dan tokopedia, masih akan dikembangkan lagi. Berikut contoh data yang diperoleh dengan crawler yang dibuat.
<img src="https://rizkidoank.sgp1.digitaloceanspaces.com/rizkidoank/images/2016/11/14522369_120300000387791878_287015246_o.png" alt="Tokopedia Item">
Sedangkan berikut adalah contoh tampilan saat ditampilkan di dasbor. Untuk dasbor saya gunakan Banana, sehingga data dari MongoDB perlu di pipeline ke Solr dahulu. Kedepannya akan menggunakan dasbor custom.
<img src="https://rizkidoank.sgp1.digitaloceanspaces.com/rizkidoank/images/2016/11/14488922_120300000346061494_118797559_o.png" alt="Banana Dashboard">
Dikarenakan kebanyakan situs telah dinamis menggunakan Javascript, downloader biasa saja rasanya tidak cukup. Ya, memang masih dapat memanfaatkan dan mencari AJAX request atau API nya. Tetapi, untuk berjaga-jaga dan tujuan pengembangan, saya menggunakan Splash yang dipasang secara terdistribusi. Splash digunakan saat tidak ada cara lain untuk mendapatkan atribut tertentu. Mungkin ada yang punya ide lain untuk crawling situs dinamis yang lebih cepat? Silakan bagikan jiga berkenan :D. Atau mungkin jika ada yang tertarik untuk mengembangkan bersama, mari.</p>
<p>Selanjutnya saya paparkan kesulitan yang ditemui saat melakukan pengembangan.</p>
<ul>
<li>Situs e-Commerce sebagian besar dinamis dengan Javascript, beberapa atribut perlu di-retrieve dengan load javascript terlebih dahulu. Dapat diatasi dengan Splash, hanya saja masih lebih lambat dibandingkan dengan HTTP request yang plain. Pada Tokopedia, saya dapat manfaatkan XHR request sehingga scraping bisa lebih cepat.</li>
<li>Memilih atribut yang tepat, tiap situs memiliki atribut yang berbeda-beda. Kalau atribut umum seperti nama, harga, dan deskripsi rasanya tidak masalah. Namun, masalahnya saya ingin agar seluruh atribut penting dapat diambil agar dapat diolah nanti, pemilihan atribut ini perlu orang yang mengerti proses bisnisnya.</li>
<li>Penentuan selektor perlu dilakukan lebih jeli, sebisa mungkin selektor tidak rumit, tetapi tepat memilih atribut yang diinginkan. Nah, bagian ini saya butuh waktu cukup lama karena seringkali saat test running, di laman tertentu selektor tersebut tidak ada. Haha.</li>
<li>Kehandalan downloader, Splash saat ini saya rasa masih paling cocok. Namun,seringkali Splash dapat crash. Maka dari itu, saya melakukan clustering Splash dengan HAProxy.</li>
<li>Politeness vs Velocity. Ini juga jadi salah satu dilemma, karena ketika Scrapy di konfigurasikan dengan concurrent request yang terlalu tinggi, diperlukan bandwidth yang lebih besar juga, sementara itu efek samping lain adalah IP kemungkinan dapat di blok karena dianggap melakukan flooding. Solusi untuk ini bisa menggunakan Rotating IP, saya manfaatkan Tor. Tetapi, dikarenakan jaringan Tor yang banyak hop, scraping menjadi lambat dan sangat mungkin terjadi request timeout.</li>
</ul>

      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "rizkidoank" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        
        
      </footer>
    </article>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js" id="MathJax-script"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'], ['\\(', '\\)']
        ],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  </script>
  </section>

      </div>

      
  <footer class="footer">
    <section class="container">
      
      
        ©
        
        2020
         Rizki Rizki 
      
      
         · 
        Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
      
      
        
      
    </section>
  </footer>

    </main>

    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-78100671-2', 'auto');
	
	ga('send', 'pageview');
}
</script>


    

  </body>

</html>
