<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>web-scraping on rizkidoank&#39;s Blog</title>
    <link>https://rizkidoank.com/tags/web-scraping/</link>
    <description>Recent content in web-scraping on rizkidoank&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Nov 2016 05:01:42 +0000</lastBuildDate>
    
	<atom:link href="https://rizkidoank.com/tags/web-scraping/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Pengalaman Membuat E-Commerce Scraper dengan Scrapy</title>
      <link>https://rizkidoank.com/2016/11/03/pengalaman-membuat-e-commerce-scraper-dengan-scrapy/</link>
      <pubDate>Thu, 03 Nov 2016 05:01:42 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/11/03/pengalaman-membuat-e-commerce-scraper-dengan-scrapy/</guid>
      <description>Beberapa bulan ini saya mengembangkan proyek berupa dasbor untuk monitoring toko online dari beberapa e-commerce. Salah satu bagian penting yang ada di proyek ini yaitu crawler / scraper. Crawler digunakan untuk akuisisi data yang selanjutnya akan diolah menjadi data penjualan terintegrasi untuk pemilik toko.
Saat ini ada beberapa framework crawler yang banyak digunakan misal saja Apache Nutch yang memiliki keunggulan untuk dapat bekerja pada Hadoop Cluster (versi 2), dan Scrapy yang berbasis Python dan mendukung mode terdistribusi dengan frontera (HBase).</description>
    </item>
    
    <item>
      <title>High Availability Splash Cluster dengan HA-Proxy</title>
      <link>https://rizkidoank.com/2016/08/29/high-availability-splash-cluster-dengan-ha-proxy/</link>
      <pubDate>Mon, 29 Aug 2016 09:19:15 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/08/29/high-availability-splash-cluster-dengan-ha-proxy/</guid>
      <description>Pada tulisan sebelumnya di Integrasi Splash dengan Scrapy, saya mencoba untuk integrasi Splash dengan Scrapy. Awalnya saya menggunakan satu kontainer Splash untuk crawling, tetapi ternyata terkendala saat menggunakan concurrent requests yang sedikit tinggi dan juga situs dengan script yang lumayan berat. Berikut dua isu utama yang sering saya temui saat crawling
 504 Gateway Timeout - umumnya error ini disebabkan oleh timeout saat fetching karena faktor tertentu, misal : script yang berat.</description>
    </item>
    
    <item>
      <title>Rendering Javascript dengan Splash</title>
      <link>https://rizkidoank.com/2016/06/16/rendering-javascript-dengan-splash/</link>
      <pubDate>Thu, 16 Jun 2016 21:18:30 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/16/rendering-javascript-dengan-splash/</guid>
      <description>Pengantar Splash Saat ini banyak cara untuk akuisisi data, salah satu yang sedang populer dikembangkan adalah web crawling. Namun, permasalahannya terkendala saat menghadapi situs web dinamis yang menggunakan javascript. &amp;lsquo;Browser&amp;rsquo; yang digunakan umumnya tidak mendukung javascript.
Splash merupakan salah satu solusi untuk menghadapi situs web dinamis. Splash adalah layanan yang digunakan sebagi rendering javascript. Layanan ini dikembangkan oleh scrapinghub dan mendukung HTTP API untuk interaksi.
Pemasangan Splash Jika mengacu pada situs dokumentasi splash, terdapat opsi untuk pemasangan Splash dengan Docker.</description>
    </item>
    
  </channel>
</rss>