<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>indonesian on rizkidoank</title>
    <link>https://rizkidoank.com/tags/indonesian/</link>
    <description>Recent content in indonesian on rizkidoank</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 24 Jul 2020 00:33:34 +0700</lastBuildDate><atom:link href="https://rizkidoank.com/tags/indonesian/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kenapa Saya Memilih Arch Linux untuk Workstation?</title>
      <link>https://rizkidoank.com/2020/07/24/kenapa-saya-memilih-arch-linux-untuk-workstation//</link>
      <pubDate>Fri, 24 Jul 2020 00:33:34 +0700</pubDate>
      
      <guid>https://rizkidoank.com/2020/07/24/kenapa-saya-memilih-arch-linux-untuk-workstation//</guid>
      <description>Linux adalah salah satu sistem operasi yang banyak dikenal oleh pengguna komputer selain Microsoft Windows dan Apple MacOS. Terlebih saat ini sudah tersedia banyak pilihan distribusi linux yang dikembangkan, bahkan ada yang dikembangkan oleh perusahaan seperti Ubuntu oleh Canonical, Red Hat Enterprise Linux oleh Red Hat, SUSE Linux Enterprise oleh SUSE. Lalu sebagai seorang pengembang aplikasi, distribusi apa yang saya pilih untuk workstation saya? Arch Linux! Kenapa? Simak lebih lanjut.</description>
    </item>
    
    <item>
      <title>Pengalaman VBAC : Cerita Kami di Tiga Minggu Terakhir</title>
      <link>https://rizkidoank.com/2020/07/24/pengalaman-vbac-cerita-kami-di-tiga-minggu-terakhir//</link>
      <pubDate>Fri, 24 Jul 2020 00:25:31 +0700</pubDate>
      
      <guid>https://rizkidoank.com/2020/07/24/pengalaman-vbac-cerita-kami-di-tiga-minggu-terakhir//</guid>
      <description>Memasuki minggu ke 38 awal, belum ada perkembangan berarti. Sehingga istri saat itu ingin coba kontrol ke dokter lain yang bukan partner saat itu. Alangkah kecewanya dan geram saya saat itu ketika memasuki ruangan, kami hanya ditanya berapa jarak kehamilan dengan operasi SC terakhir. Lalu, tanpa penjelasan apapun langsung berkata kurang lebih seperti ini &amp;ldquo;SC lagi ya, jam 10 saya kosong, mau ga? Atau kalau ga mau hari ini ya hari Selasa&amp;rdquo; (kami di dokter tersebut sekitar jam 07:00 WIB).</description>
    </item>
    
    <item>
      <title>Pengalaman VBAC : Tips dan Informasi</title>
      <link>https://rizkidoank.com/2020/07/24/pengalaman-vbac-tips-dan-informasi//</link>
      <pubDate>Fri, 24 Jul 2020 00:18:11 +0700</pubDate>
      
      <guid>https://rizkidoank.com/2020/07/24/pengalaman-vbac-tips-dan-informasi//</guid>
      <description>Anak pertama saya dilahirkan dengan metode sectio caesaria (SC). Waktu itu, pada usia 37 minggu akhir kami kontrol ke dokter kandungan dan dinyatakan bahwa air ketuban keruh, sehingga diperlukan tindakan operasi SC. Saat itu juga dicoba induksi, diharapkan dapat menstimulasi terjadinya kelahiran spontan. Namun, hingga batas waktu yang disepakati, belum ada perkembangan berarti. Selain itu, perlu diketahui bahwa saya kurang tau pasti detail kenapa air ketuban saat itu keruh, padahal awal minggu ke 37 masih sangat baik kondisinya.</description>
    </item>
    
    <item>
      <title>Pengalaman Sertifikasi CKA</title>
      <link>https://rizkidoank.com/2020/07/16/pengalaman-sertifikasi-cka//</link>
      <pubDate>Thu, 16 Jul 2020 19:29:31 +0700</pubDate>
      
      <guid>https://rizkidoank.com/2020/07/16/pengalaman-sertifikasi-cka//</guid>
      <description>Sertifikasi merupakan salah satu cara untuk melakukan pengembangan diri. Sampai tulisan ini ditulis, saya terbilang jarang mengambil sertifikasi karena pada umumnya sertifikasi dilakukan onsite di lokasi tertentu. Alasan lainnya adalah biaya yang perlu dikeluarkan untuk mengambil ujian untuk beberapa sertifikasi terbilang mahal untuk saya.
Tentang Certified Kubernetes Administrator (CKA) Certified Kubernetes Administrator (CKA) adalah program sertifikasi yang didukung oleh Cloud Native Computing Foundation (CNCF) sebagai bentuk upaya pengembangan ekosistem Kubernetes. Pada CKA, sertifikasi lebih ditujukan untuk administrator Kubernetes untuk mendemonstrasikan kemampuannya dalam instalasi, konfigurasi, manajemen, dan troubleshooting klaster Kubernetes.</description>
    </item>
    
    <item>
      <title>Eksplorasi Data dengan R</title>
      <link>https://rizkidoank.com/2016/12/12/eksplorasi-data-dengan-r//</link>
      <pubDate>Mon, 12 Dec 2016 04:07:14 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/12/12/eksplorasi-data-dengan-r//</guid>
      <description>Dalam data science sebelum dilakukan analisis data lebih lanjut, ada baiknya dilakukan dahulu eksplorasi data. Eksplorasi data juga disarankan untuk yang baru memasuki data science. Dengan eksplorasi data, dapat diketahui apa saja atribut pada dataset, bagaimana nilai-nilai yang ada dalam dataset, distribusi data, atau keterhubungan suatu atribut dengan atribut lainnya.
Pada tulisan ini saya mencoba untuk eksplorasi data dan beberapa visualisasinya untuk dataset Iris dari UCI Machine Learning Repository. Berikut adalah ekplorasi data yang saya lakukan untuk dataset iris.</description>
    </item>
    
    <item>
      <title>SparkR Installation and Setup on RStudio</title>
      <link>https://rizkidoank.com/2016/12/10/sparkr-installation-and-setup-on-rstudio//</link>
      <pubDate>Sat, 10 Dec 2016 12:17:37 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/12/10/sparkr-installation-and-setup-on-rstudio//</guid>
      <description>Apache Spark adalah mesin pemrosesan data yang cepat yang saat ini umum digunakan pada big data environment dan untuk pembelajarn mesin. Spark mendukung beberapa bahasa seperti Java, Scala, Python dan saat ini hadir untuk bahasa R.
Spark dapat dipasang pada mode lokal maupun mode cluster. Dalam tulisan ini akan dipaparkan pemasangan SparkR pada mode lokal. Berikut adalah langkah pemasangan SparkR + RStudio.
  Pastikan RStudio, R, dan Java JDK telah terpasang.</description>
    </item>
    
    <item>
      <title>Pengalaman Membuat E-Commerce Scraper dengan Scrapy</title>
      <link>https://rizkidoank.com/2016/11/03/pengalaman-membuat-e-commerce-scraper-dengan-scrapy//</link>
      <pubDate>Thu, 03 Nov 2016 05:01:42 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/11/03/pengalaman-membuat-e-commerce-scraper-dengan-scrapy//</guid>
      <description>Beberapa bulan ini saya mengembangkan proyek berupa dasbor untuk monitoring toko online dari beberapa e-commerce. Salah satu bagian penting yang ada di proyek ini yaitu crawler / scraper. Crawler digunakan untuk akuisisi data yang selanjutnya akan diolah menjadi data penjualan terintegrasi untuk pemilik toko.
Saat ini ada beberapa framework crawler yang banyak digunakan misal saja Apache Nutch yang memiliki keunggulan untuk dapat bekerja pada Hadoop Cluster (versi 2), dan Scrapy yang berbasis Python dan mendukung mode terdistribusi dengan frontera (HBase).</description>
    </item>
    
    <item>
      <title>Ekosistem Hadoop pada Big Data</title>
      <link>https://rizkidoank.com/2016/11/02/ekosistem-hadoop-pada-big-data//</link>
      <pubDate>Wed, 02 Nov 2016 21:35:58 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/11/02/ekosistem-hadoop-pada-big-data//</guid>
      <description>Big Data, Hadoop? Kata Big Data sempat menjadi hype di kalangan scientist dan IT enthusiast. Adapun salah satu yang banyak dibicarakan dan didiskusikan salah satunya terkait dengan infrastruktur Big Data. Bagi yang pernah mencoba belajar infrastruktur Big Data, setidaknya akan terdengar kata seperti Hadoop, Cluster, NoSQL, dan Distributed System (setidaknya itu yang pertama kali terdengar oleh saya saat akan belajar infrastruktur Big Data :D).
Ekosistem Hadoop Hadoop salah satu proyek yang dikembangkan oleh Apache Foundation.</description>
    </item>
    
    <item>
      <title>Deploy Ghost Blog di CPanel</title>
      <link>https://rizkidoank.com/2016/10/24/deploy-ghost-blog-di-cpanel//</link>
      <pubDate>Mon, 24 Oct 2016 08:50:49 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/10/24/deploy-ghost-blog-di-cpanel//</guid>
      <description>Ghost adalah blogging platform berbasis nodejs. Blog rizkidoank.com menggunakan Ghost, dan jujur saja saya sangat menikmati blogging dengan platform ini.
Biasanya Ghost dipasang di VPS atau PaaS seperti Heroku misalnya. Di Indonesia, harga sewa VPS masih cukup tinggi, selain itu performa yang diberikan juga masih lebih lambat dari VPS di provider luar. Oleh karena itu, masih banyak yang memanfaatkan hosting dikarenakan harga yang lebih terjangkau dan pengguna tidak perlu pusing dalam konfigurasi server.</description>
    </item>
    
    <item>
      <title>Double Linked List</title>
      <link>https://rizkidoank.com/2016/10/17/double-linked-list//</link>
      <pubDate>Mon, 17 Oct 2016 08:52:18 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/10/17/double-linked-list//</guid>
      <description>Pengenalan Double Linked List Pengertian Double Linked List adalah sekumpulan node data yang terurut linear atau sekuensial dengan dua buah pointer yaitu prev dan next. Double Linked List adalah linked list dengan node yang memiliki data dan dua buah reference link (biasanya disebut next dan prev) yang menunjuk ke node sebelum dan node sesudahnya. Pada implementasinya, terdapat dua variasi double linked list yaitu circular dan non-circular layaknya pada single linked list.</description>
    </item>
    
    <item>
      <title>Remote Desktop Real Display dengan VNC</title>
      <link>https://rizkidoank.com/2016/10/14/remote-desktop-real-display-dengan-vnc//</link>
      <pubDate>Fri, 14 Oct 2016 06:03:16 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/10/14/remote-desktop-real-display-dengan-vnc//</guid>
      <description>Beberapa minggu lalu sempat ramai berita tentang videotron di Jakarta Selatan yang di &amp;ldquo;retas&amp;rdquo; oleh seseorang. Berdasarkan dari berita-berita terakhir, pelaku melakukan aksinya dikarenakan tahu akses ke videotron tersebut karena saat ia melintas, username dan password terlihat di videotron tersebut.
Sebenarnya, kejadian tersebut cukup menggelitik bagi saya. Nah, pada tulisan ini saya akan berbagi salah satu solusi yang mungkin bisa diterapkan pada videotron tersebut tanpa khawatir akses terlihat.
VNC (Virtual Network Computing) adalah sistem desktop sharing yang memanfaatkan protokol Remote Frame Buffer.</description>
    </item>
    
    <item>
      <title>MariaDB Load Balancing</title>
      <link>https://rizkidoank.com/2016/10/13/mariadb-load-balancing//</link>
      <pubDate>Thu, 13 Oct 2016 03:40:00 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/10/13/mariadb-load-balancing//</guid>
      <description>MySQL atau MariaDB seringkali digunakan untuk DBMS relasional. Pada penggunaan pribadi atau skala kecil menengah, satu instance MySQL atau MariaDB sudah cukup untuk memenuhi kebutuhan. Namun, pada skala besar, seringkali ditemukan kendala seperti tidak mampu menangani rekues, eksekusi kueri yang lambat, dan lain-lain.
Dalam menanggapi permasalahan tersebut, terdapat beberapa solusi yang dapat diterapkan antara lain tuning di DBMS,tuning di level sistem operasi, scale-up,atau load balancing. Pada tulisan ini saya akan mencoba melakukan load balancing MariaDB.</description>
    </item>
    
    <item>
      <title>Single Linked List</title>
      <link>https://rizkidoank.com/2016/10/11/single-linked-list//</link>
      <pubDate>Tue, 11 Oct 2016 04:47:08 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/10/11/single-linked-list//</guid>
      <description>Pengertian Single Linked List Linked List adalah sekumpulan node data yang terurut linear atau sekuensial. Node adalah istilah untuk elemen pada suatu list. Pada kondisi paling sederhana,node memiliki setidaknya dua atribut yaitu data dan referensi untuk node selanjutnya.
Single Linked List adalah linked list dengan node yang memiliki data dan reference link (biasanya disebut next) yang menunjuk ke node lain pada list. Pada implementasinya, terdapat dua variasi single linked list yaitu circular dan non-circular.</description>
    </item>
    
    <item>
      <title>Memasang Oracle JDK di Linux</title>
      <link>https://rizkidoank.com/2016/10/10/memasang-oracle-jdk-di-linux//</link>
      <pubDate>Mon, 10 Oct 2016 08:03:58 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/10/10/memasang-oracle-jdk-di-linux//</guid>
      <description>Oracle JDK (Java Development Kit) adalah development kit Java yang disediakan oleh Oracle. Oracle JDK banyak digunakan untuk proyek berbasis Java di skala enterprise, Oracle JDK juga menyediakan library yang hanya tersedia dibawah distribusi paket ini.
Pada distribusi Linux, JDK yang disediakan pada repositori adalah OpenJDK. Pada beberapa kondisi, OpenJDK tidak dapat digunakan oleh aplikasi tertentu. Pada tulisan ini saya akan berbagi cara memasang Oracle JDK di sistem operasi Linux dengan sampel distribusi yaitu Ubuntu.</description>
    </item>
    
    <item>
      <title>Tutorial REST API CRUD dengan NodeJS</title>
      <link>https://rizkidoank.com/2016/10/03/tutorial-rest-api-crud-dengan-nodejs//</link>
      <pubDate>Mon, 03 Oct 2016 08:12:00 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/10/03/tutorial-rest-api-crud-dengan-nodejs//</guid>
      <description>Setelah mengenal REST API pada post sebelumnya di Pengantar REST API, saya akan membuat contoh REST API untuk CRUD dengan contoh model yaitu User.
Desain REST API Berikut adalah desain API yang akan saya buat,
System Requirements Untuk dapat membuat API ini, saya menggunakan perangkat sebagai berikut:
 NodeJS LTS dengan NVM, pemasangan dapat dibaca di Setup NodeJS dan MongoDB di Linux. MongoDB, dapat gunakan tautan yang sama untuk contoh pemasangannya.</description>
    </item>
    
    <item>
      <title>Pengantar REST API</title>
      <link>https://rizkidoank.com/2016/09/30/pengantar-rest-api//</link>
      <pubDate>Fri, 30 Sep 2016 03:19:13 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/09/30/pengantar-rest-api//</guid>
      <description>REST API banyak digunakan saat akan membuat aplikasi. Dengan REST API saya dapat membuat aplikasi yang multiplatform, karena saya tidak perlu implementasikan fungsi-fungsi CRUD (misalnya) pada tiap platform. Saya cukup menggunakan API yang disediakan untuk memanipulasi basis data yang digunakan aplikasi.
Gambar diatas merupakan diagram dari REST API. Biasanya pada REST API memanfaatkan HTTP Request, misal seperti GET untuk ambil data, POST untuk masukkan data, PUT untuk pembaharuan data, DELETE untuk hapus data.</description>
    </item>
    
    <item>
      <title>Message Queue Telemetry Transport (MQTT)</title>
      <link>https://rizkidoank.com/2016/09/29/message-queue-telemetry-transport-mqtt//</link>
      <pubDate>Thu, 29 Sep 2016 12:30:02 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/09/29/message-queue-telemetry-transport-mqtt//</guid>
      <description>Message Queue Telemetry Transport (MQTT) adalah protokol layer aplikasi yang didesain khusus untuk constrained-device [1]. Constrained-device yang dimaksud disini yaitu perangkat yang memiliki keterbatasan disisi resources. MQTT menggunakan arsitektur dengan model topic-based publish-subscribe.
Pada MQTT, akan ada setidaknya tiga pemeran utama yaitu publisher, subscriber, dan broker (lihat gambar diatas). Publisher adalah peran yang memberikan suatu pesan kepada topik tertentu. Subscriber yaitu klien yang subscribe suatu topik, sehingga ketika publisher mengirimkan pesan ke topik tersebut, subscriber dengan topik yang sama akan menerima pesan tersebut.</description>
    </item>
    
    <item>
      <title>Instalasi Mosquitto di Alpine Linux</title>
      <link>https://rizkidoank.com/2016/09/26/instalasi-mosquitto-di-alpine-linux//</link>
      <pubDate>Mon, 26 Sep 2016 08:10:38 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/09/26/instalasi-mosquitto-di-alpine-linux//</guid>
      <description>Mosquitto adalah broker MQTT opensource. MQTT adalah protokol konektivitas Machine-to-Machine (M2M) atau Internet of Things. MQTT dirancang seringan mungkin dengan menggunakan model publish dan subscribe. Untuk lebih lanjut mengenai MQTT dapat dibaca melalui referensi lain, atau mungkin akan saya post juga di blog ini baca tulisan berikut Message Queue Telemetry Transport (MQTT).
Saya akan melakukan pemasangan Mosquitto untuk MQTT broker dengan Alpine Linux dengan mesin virtual. Sedangkan untuk klien publish dan subscribe saya gunakan host utama.</description>
    </item>
    
    <item>
      <title>Iseng, RAID0 dengan USB Flash Drive</title>
      <link>https://rizkidoank.com/2016/09/20/iseng-raid0-dengan-usb-flash-drive//</link>
      <pubDate>Tue, 20 Sep 2016 08:49:09 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/09/20/iseng-raid0-dengan-usb-flash-drive//</guid>
      <description>RAID adalah teknik striping, mirroring, atau paritas untuk membentuk penyimpanan yang handal dengan memanfaatkan beberapa disk. Terdapat beberapa jenis level pada RAID, di tulisan selanjutnya mungkin saya bisa memaparkan beberapa :D.
Nah, Biasanya RAID diimplementasikan dengan disk seperti HDD ataupun SSD. Sekarang, saya ingin mencoba membuat RAID dengan dua buah Flash Drive dengan RAID0.
Barang dan Bahan Barang yang dibutuhkan yaitu dua buah Flash Drive. Berikut Flash Drive yang saya gunakan, masing-masing DISK1 dan DISK2.</description>
    </item>
    
    <item>
      <title>Setup Node.JS dan MongoDB di Linux</title>
      <link>https://rizkidoank.com/2016/09/20/setup-node.js-dan-mongodb-di-linux//</link>
      <pubDate>Tue, 20 Sep 2016 03:25:53 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/09/20/setup-node.js-dan-mongodb-di-linux//</guid>
      <description>Node.JS dan MongoDB adalah perangkat lunak populer saat ini. Platform Node.JS dan Database MongoDB banyak digunakan untuk membuat aplikasi real-time. Pada kesempatan ini saya akan melakukan setup dan konfigurasi Node.JS dan MongoDB di Linux.
Setup Node.JS Beberapa distribusi Linux sudah terdapat paket Node.JS di repositorinya. Tetapi, kali ini saya akan memasangnya dengan Node Version Manager (NVM) oleh creationix. Karena, NVM memungkinkan user menggunakan beberapa versi node.js dan lebih baik dalam manajemen paket (tidak mengganggu sistem, pemasangan paket global tidak perlu akses root).</description>
    </item>
    
    <item>
      <title>High Availability Splash Cluster dengan HA-Proxy</title>
      <link>https://rizkidoank.com/2016/08/29/high-availability-splash-cluster-dengan-ha-proxy//</link>
      <pubDate>Mon, 29 Aug 2016 09:19:15 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/08/29/high-availability-splash-cluster-dengan-ha-proxy//</guid>
      <description>Pada tulisan sebelumnya di Integrasi Splash dengan Scrapy, saya mencoba untuk integrasi Splash dengan Scrapy. Awalnya saya menggunakan satu kontainer Splash untuk crawling, tetapi ternyata terkendala saat menggunakan concurrent requests yang sedikit tinggi dan juga situs dengan script yang lumayan berat. Berikut dua isu utama yang sering saya temui saat crawling
 504 Gateway Timeout - umumnya error ini disebabkan oleh timeout saat fetching karena faktor tertentu, misal : script yang berat.</description>
    </item>
    
    <item>
      <title>Integrasi Splash dengan Scrapy</title>
      <link>https://rizkidoank.com/2016/08/18/integrasi-splash-dengan-scrapy//</link>
      <pubDate>Thu, 18 Aug 2016 06:05:01 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/08/18/integrasi-splash-dengan-scrapy//</guid>
      <description>Pada tulisan sebelumnya di Rendering Javascript dengan Splash saya telah menulis pengantar dari Splash. Splash adalah salah satu javascript rendering service berbasis WebKit dan layanan ini bersifat headless.
Scrapy merupakan salah satu web scraper framework berbasis python yang cukup populer. Pada kondisi default, scrapy tidak mampu melakukan javascript rendering / dynamic webpage load, sehingga diperlukan pihak aplikasi tambahan seperti Selenium atau Splash.
Pada tulisan ini saya akan memaparkan cara integrasi Scrapy dengan Splash sebagai dynamic webpage rendering service.</description>
    </item>
    
    <item>
      <title>Rendering Javascript dengan Splash</title>
      <link>https://rizkidoank.com/2016/06/16/rendering-javascript-dengan-splash//</link>
      <pubDate>Thu, 16 Jun 2016 21:18:30 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/16/rendering-javascript-dengan-splash//</guid>
      <description>Pengantar Splash Saat ini banyak cara untuk akuisisi data, salah satu yang sedang populer dikembangkan adalah web crawling. Namun, permasalahannya terkendala saat menghadapi situs web dinamis yang menggunakan javascript. &amp;lsquo;Browser&amp;rsquo; yang digunakan umumnya tidak mendukung javascript.
Splash merupakan salah satu solusi untuk menghadapi situs web dinamis. Splash adalah layanan yang digunakan sebagi rendering javascript. Layanan ini dikembangkan oleh scrapinghub dan mendukung HTTP API untuk interaksi.
Pemasangan Splash Jika mengacu pada situs dokumentasi splash, terdapat opsi untuk pemasangan Splash dengan Docker.</description>
    </item>
    
    <item>
      <title>Akses File di Platform Blog Ghost</title>
      <link>https://rizkidoank.com/2016/06/15/akses-file-di-platform-blog-ghost//</link>
      <pubDate>Wed, 15 Jun 2016 22:59:25 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/15/akses-file-di-platform-blog-ghost//</guid>
      <description>Setelah saya menggunakan Ghost untuk blog ini, rasanya cukup nyaman. Ghost jauh lebih ringan dan sederhana dibandingkan blogging platform yang pernah saya pakai sebelumnya. Hanya saja, terdapat kendala saat ingin mengunggah berkas selain gambar di Ghost.
Unggah berkas seringkali digunakan pada beberapa posting, misal seperti pada posting Twitter Mining with R : Tweet Analysis, Bagian 2, disitu saya ingin melampirkan berkas berupa dataset dan berkas stopword Indonesia. Saya sempat bingung untuk mengunggah ke server.</description>
    </item>
    
    <item>
      <title>Twitter Mining with R : Tweet Analysis, Bagian 3</title>
      <link>https://rizkidoank.com/2016/06/13/twitter-mining-with-r-tweet-analysis-bagian-3//</link>
      <pubDate>Mon, 13 Jun 2016 07:01:36 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/13/twitter-mining-with-r-tweet-analysis-bagian-3//</guid>
      <description>Pada post sebelumnya di Twitter Mining with R : Tweet Analysis, Bagian 2, saya sudah mencoba untuk melakukan Text Cleaning untuk dataset yang ada. Selanjutnya, pada bagian ini saya akan mencoba membuat statistik term frequency dan juga membuat wordcloud dari term document frequency.
Statistik Terms Frequency Sebelumnya, saya memiliki variabel tdm yang merupakan term document frequency. Nah, untuk membuat plot statistik frekuensi term saya menggunakan ggplot2, terlebih dahulu install paket ggplot2 dengan perintah install.</description>
    </item>
    
    <item>
      <title>Tutorial Pemasangan CentOS 6 di Server</title>
      <link>https://rizkidoank.com/2016/06/13/tutorial-pemasangan-centos-6-di-server//</link>
      <pubDate>Mon, 13 Jun 2016 04:54:09 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/13/tutorial-pemasangan-centos-6-di-server//</guid>
      <description>CentOS adalah distribusi linux berbasis Red Hat Enterprise Linux (RHEL). CentOS dikelola oleh komunitas dan dapat diunduh secara gratis dari situs resminya. Manajemen paket yang digunakan adalah RPM, sama halnya dengan RHEL. CentOS umum digunakan untuk server. Pada post ini, saya akan berbagi mengenai Tutorial Instalasi CentOS 6. Dalam hal ini, akan digunakan CentOS 6.7 Minimal yang dapat diunduh di situs CentOS.
Tutorial menggunakan mesin virtual KVM dengan spesifikasi satu core CPU, memori 1GB, satu NIC, HDD 15GB.</description>
    </item>
    
    <item>
      <title>Twitter Mining with R : Tweet Analysis, Bagian 2</title>
      <link>https://rizkidoank.com/2016/06/12/twitter-mining-with-r-tweet-analysis-bagian-2//</link>
      <pubDate>Sun, 12 Jun 2016 16:54:57 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/12/twitter-mining-with-r-tweet-analysis-bagian-2//</guid>
      <description>Pengantar Pada tulisan ini akan melanjutkan proses selanjutnya setelah mendapatkan data dengan Twitter API. Jika ingin mengunduh dataset tanpa mengambil online dari twitter, silakan unduh melalui link berikut :
 Tweet @RadioElshinta Stopwords Indonesia  Text Cleaning Setelah akuisisi data, langkah selanjutnya adalah Text Cleaning . Tahapan ini meliputi sub-proses antara lain stopwords removal, whitespaces stripping, dan stemming.
library(tm)library(SnowballC)load(file = &amp;quot;elshinta.RData&amp;quot;)tweets.df &amp;lt;- twListToDF(tweets_data)corpus &amp;lt;- Corpus(VectorSource(tweets.df$text))# lowercase kontencorpus &amp;lt;- tm_map(corpus,content_transformer(tolower))# hapus url, dan tanda bacaremoveURL &amp;lt;- function(x) gsub(&amp;quot;http[^[:space:]]*&amp;quot;, &amp;quot;&amp;quot;, x)corpus &amp;lt;- tm_map(corpus, content_transformer(removeURL))corpus &amp;lt;- tm_map(corpus, removePunctuation)# buat stopwords Indonesiafile_stop &amp;lt;- file(&amp;quot;stopwords.</description>
    </item>
    
    <item>
      <title>Twitter Mining with R : Tweet Analysis, Bagian 1</title>
      <link>https://rizkidoank.com/2016/06/11/twitter-mining-with-r-tweet-analysis-bagian-1//</link>
      <pubDate>Sat, 11 Jun 2016 17:41:08 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/11/twitter-mining-with-r-tweet-analysis-bagian-1//</guid>
      <description>Pengantar Pada tulisan sebelumnya, Introduction to Twitter Mining with R telah dipaparkan pengantar tentang Text Mining pada Twitter dengan R. Pada tulisan ini akan dibahas tentang Tweet Analysis. Secara utuh, yang akan saya lakukan adalah :
 Mengambil data tweet dengan R menggunakan paket twitteR. Text cleaning dengan paket tm pada R. Menampilkan Terms Frequency Membuat wordcloud berdasar term yang didapat.  Mengambil Data Tweets Sebelumnya, pastikan telah membuat Twitter App seperti pada tulisan sebelumnya.</description>
    </item>
    
    <item>
      <title>Introduction to Twitter Mining with R</title>
      <link>https://rizkidoank.com/2016/06/11/introduction-to-twitter-mining-with-r//</link>
      <pubDate>Sat, 11 Jun 2016 16:20:01 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/11/introduction-to-twitter-mining-with-r//</guid>
      <description>Pengantar Twitter dan Twitter Apps Twitter adalah media sosial berbasis teks dengan maksimal huruf sebanyak 140 dalam satu tulisan (disebut tweet). Twitter kerapkali digunakan sebagai sumber data untuk diolah karena akuisisi data tidak terlalu kompleks jika dibandingkan media sosial lain.
Untuk mengambil data pada twitter, kita dapat memanfaatkan Twitter Application. Ikuti langkah berikut:
 Buka Twitter Apps. Buat app baru dengan klik create new app. Isi detail app, lanjutkan. App baru akan dibuat, contohnya adalah gambar berikut.</description>
    </item>
    
    <item>
      <title>RStudio : IDE untuk R</title>
      <link>https://rizkidoank.com/2016/06/11/rstudio-ide-untuk-r//</link>
      <pubDate>Sat, 11 Jun 2016 00:03:09 +0000</pubDate>
      
      <guid>https://rizkidoank.com/2016/06/11/rstudio-ide-untuk-r//</guid>
      <description>Pengantar R adalah perangkat lunak yang dikembangkan oleh R Foundation dan merupakan bagian dari GNU Project. Pada situs resminya di r-project dikatakan bahwa :
 R is a free software environment for statistical computing and graphics. It compiles and runs on a wide variety of UNIX platforms, Windows and MacOS.
 R digunakan untuk keperluan komputasi statistik dan grafik, mirip dengan Matlab namun R bersifat Free Software dengan lisensi GNU Public License.</description>
    </item>
    
  </channel>
</rss>
